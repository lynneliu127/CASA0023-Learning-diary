---
bibliography: references.bib
---

# Classification II

## Overview {.unnumbered}

-   Summary
-   Application
-   Reflection

## Summary

### How consider / process EO data ?

1.  **Pixel**: Pixel-based analysis, spectral unmixing

2.  **Objects** (image objects or segments): object-based image analysis (OBIA)

3.  **Mixed** **pixels**: spectral decomposition, sub-image classification

4.  **Mixed** **objects**: hierarchical classification, multi-resolution data fusion

### What data should we use assess the accuracy of our classification models ?

1.  New dataset to test the output with

2.  Train / split the training data

3.  **Cross-validation:**Reduce the chance of model evaluation by dividing the dataset into subsets and iteratively performing training and validation.

    -   k-fold cross-validation

    -   Leave-One-Out Cross-Validation, LOOCV

    -   Stratified k-fold cross-validation

    -   Time Series Cross-Validation

### When we have a test dataset how do we assess the accuracy ?

1.  **Confusion Matrix:** Evaluates the performance of a classification model, showing the relationship between the actual categories and the categories predicted by the model.

    -   True Positives (TP): the number of correctly predicted true positives.

    -   False Positives (FP): the number of negative cases that are incorrectly predicted as positive cases.

    -   True Negatives (TN): the number of correctly predicted negative examples.

    -   False Negatives (FN): the number of positive examples that were incorrectly predicted to be negative.

2.  **Accuracy:**Indicates the proportion of samples correctly predicted by the model to the total samples.

    Formula:

    $$
    \text{Accuracy} = \frac{TP + TN}{TP + TN + FP + FN}
    $$

3.  **Precision and Recall**

    -   Precision (also known as positive predictive value) is the proportion of positive categories predicted by the model that are actually positive:\
        $$
        \text{Precision} = \frac{TP}{TP + FP} 
        $$
    -   Recall (also known as sensitivity or true instance rate) is the proportion of positive categories correctly identified by the model to all actual positive categories: $$
        \text{Recall} = \frac{TP}{TP + FN}
        $$

4.  **F1 score:** the reconciled average of precision and recall, which is a composite of the two indicators: $$
    F1 = 2 \times \frac{\text{Precision} \times \text{Recall}}{\text{Precision} + \text{Recall}}
    $$

5.  **ROC Curve and AUC**

    ROC (Receiver Operating Characteristic) curve: shows the relationship between the true case rate (recall) and the false positive case rate (1 - true negative case rate) of the model at different thresholds.

    AUC (Area Under the Curve): the area under the ROC curve, the larger the value, the better the model performance.

6.  **Kappa coefficient**

    Applied to assess the accuracy of remote sensing image classification.

### When training and testing our classification models do we need to consider spatial autocorrelation?

1.  **Object-Based Image Analysis, OBIA**

    -   Image segmentation: The segmentation of an image into a number of coherent, mutually independent regions or objects. Each object is a collection of neighbouring pixels with similar spectral, textural or geometric features.

    -   Feature Extraction: extracting features from each object, which can include shape, size, texture, colour or relative position to other objects.

    -   Object Classification: based on the extracted features, each object is classified using various classification algorithms (e.g., Support Vector Machines, Random Forests, or Neural Networks).

    -   Post-processing: may include steps such as merging of objects, elimination of classification errors, boundary smoothing, etc. to improve the accuracy and usability of the classification results.

2.  **Spatial cross validation**

    -   Validation of spatial models: In the fields of ecological models, climate models, geological models, etc., it is used to validate the predictive ability of models at unknown spatial locations.

    -   Geographically Weighted Regression (GWR): to assess the prediction accuracy and stability of geographically weighted models.

    -   Remote Sensing Image Classification (RSIC): Evaluates image classification models in different geographic regions to ensure the validity of the models in brand new regions.

## Application

The application of Object-Based Image Analysis (OBIA) within the framework of Google Earth Engine (GEE) provides a nuanced understanding of the potential and complexity involved in modern remote sensing techniques. The advantages of OBIA in dealing with the spatial heterogeneity and complex morphology of urban landscapes are demonstrated by exploring the integration of high-resolution satellite data from Sentinel-1, Sentinel-2, and PlanetScope into maps of informal settlements. The importance of understanding the impact of these choices on the final classification output through the selection of appropriate segmentation parameters and the The segmentation process, which clusters pixels into meaningful objects, is key to determining the accuracy of subsequent classifications[@bar2020].

![LULC object-based classification maps using combined PL, S2 and S1 data](week8/land-12-00099-g003.webp)

In addition, the study integrates texture analyses and spectral data within the OBIA framework, highlighting the potential for improved classification results. Textural features can provide additional contextual information, which is particularly valuable in urban environments where the structural complexity of the landscape can confound traditional classification methods. Essentially, my experience of using OBIA in GEE reinforces my understanding that whilst this approach provides a powerful toolkit for detailed and nuanced land cover mapping, it requires a deep understanding of both the data and the underlying algorithms.

## Reflection

I came to appreciate the complexity and nuanced expertise of the field by understanding how Earth Observation (EO) data is considered and processed. Delving into pixel-based analysis and object-based image analysis (OBIA), I realised the importance of choosing the right approach based on the specific characteristics of the data and research objectives. Learning the various strategies for assessing the accuracy of classification models was particularly enlightening. It is not just about applying the methods, but also about understanding the rationale behind each method and how they contribute to the robustness of the model. Experimenting with cross-validation techniques (e.g., k-fold and LOOCV) made me realise the importance of thorough model evaluation to ensure that the models I created not only handled my data well, but were truly predictive and reliable.

The practical application of metrics such as confusion matrices, precision, recall and F1 scores transformed from theoretical concepts to tools that enhanced my analytical skills and provided me with a clear lens through which I could evaluate and refine my models. The exploration of ROC curves and Kappa coefficients further deepened my understanding of model performance evaluation, providing a comprehensive view of accuracy, not just percentage correct.
